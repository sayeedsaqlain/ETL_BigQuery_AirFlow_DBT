# ETL_BigQuery_AirFlow_DBT
In this ETL project, I upload raw data to a GCS Bucket and automatically ingest it into a BigQuery table using the Astro SDK with the load file operator. Implement data quality checks using Soda and an external Python operator to execute code in a virtual environment. Create dbt models to generate dimension and fact tables using Cosmos to integrate dbt with Airflow. Perform additional quality checks on the transformed data. Finally, create a dashboard visuals using Metabase/ Looker.

## Architecture

<img width="1509" alt="Screenshot 2023-07-13 at 16 41 19" src="https://github.com/sayeedsaqlain/ETL_BigQuery_AirFlow_DBT/assets/41228969/b9c837ae-eb67-4a7b-9c0d-382ba9c86fa3">

## Data Modeling

<img width="718" alt="Screenshot 2023-07-13 at 16 59 35" src="https://github.com/sayeedsaqlain/ETL_BigQuery_AirFlow_DBT/assets/41228969/bde587ad-f424-4d94-b363-9d77aa78befe">

## Screenshots
1.BigQuery

![image](https://github.com/sayeedsaqlain/ETL_BigQuery_AirFlow_DBT/assets/41228969/e2f0a9c1-af07-47dd-a5e0-e5946a752e18)

2.VS Code

![image](https://github.com/sayeedsaqlain/ETL_BigQuery_AirFlow_DBT/assets/41228969/467cbca0-524a-479d-ab69-e57ef00187da)

3.AirFlow

![image](https://github.com/sayeedsaqlain/ETL_BigQuery_AirFlow_DBT/assets/41228969/2cdceb08-18f1-4f56-8a71-403364096b0c)
